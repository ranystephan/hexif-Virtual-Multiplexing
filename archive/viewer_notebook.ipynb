{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ”¬ HEXIF Core Viewer\n",
        "\n",
        "Interactive visualization for H&E â†’ ORION predictions.\n",
        "\n",
        "**Usage:** Run all cells, then use the interactive widgets to explore cores and channels.\n",
        "\n",
        "**Works with Sherlock OnDemand** â€” No port forwarding needed!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# CONFIGURATION - Edit these paths for your setup\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "PAIRS_DIR = \"core_patches_npy\"  # Directory with core_*_HE.npy and core_*_ORION.npy\n",
        "CHECKPOINT_PATH = \"\"  # Path to model checkpoint (leave empty for view-only mode)\n",
        "SCALER_PATH = \"\"  # Path to orion_scaler.json (optional if in checkpoint)\n",
        "\n",
        "# Inference settings (only used if checkpoint provided)\n",
        "PATCH_SIZE = 224\n",
        "STRIDE = 112\n",
        "DEVICE = \"cpu\"  # \"cpu\", \"cuda\", or \"cuda:0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Imports and Setup\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "from typing import Optional, List, Dict, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import Normalize\n",
        "from IPython.display import display, clear_output\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# Optional torch imports\n",
        "try:\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import torch.nn.functional as F\n",
        "    import torchvision.transforms as T\n",
        "    HAS_TORCH = True\n",
        "except ImportError:\n",
        "    HAS_TORCH = False\n",
        "    print(\"âš ï¸ PyTorch not available - running in view-only mode\")\n",
        "\n",
        "try:\n",
        "    import timm\n",
        "    HAS_TIMM = True\n",
        "except ImportError:\n",
        "    HAS_TIMM = False\n",
        "\n",
        "print(f\"âœ… Imports complete | PyTorch: {HAS_TORCH} | timm: {HAS_TIMM}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Marker Names and Colormaps\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "MARKER_NAMES = [\n",
        "    \"DAPI\", \"CD3\", \"CD31\", \"CD45\", \"CD34\",\n",
        "    \"FoxP3\", \"CD56\", \"CD8\", \"CD11c\", \"PARP1\",\n",
        "    \"CD206\", \"CD7\", \"HLA-DR\", \"Ki67\", \"Podoplanin\",\n",
        "    \"CD4\", \"CA9\", \"Vimentin\", \"PD1\", \"CD11b\",\n",
        "]\n",
        "\n",
        "COLORMAPS = [\n",
        "    \"viridis\", \"magma\", \"plasma\", \"inferno\", \"cividis\",\n",
        "    \"Greens\", \"Blues\", \"Reds\", \"Purples\", \"Oranges\",\n",
        "    \"hot\", \"turbo\", \"coolwarm\", \"gray\", \"bone\"\n",
        "]\n",
        "\n",
        "N_CHANNELS = len(MARKER_NAMES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Utility Functions\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "def _np_to_float01(a: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Normalize array to [0, 1] float32.\"\"\"\n",
        "    if a.dtype == np.uint8:\n",
        "        a = a.astype(np.float32) / 255.0\n",
        "    elif a.dtype in (np.uint16, np.int16):\n",
        "        a = a.astype(np.float32)\n",
        "        if a.max(initial=0.0) > 1.5:\n",
        "            a = a / (np.percentile(a, 99.9) + 1e-6)\n",
        "    elif a.dtype != np.float32:\n",
        "        a = a.astype(np.float32)\n",
        "    if a.max(initial=0.0) > 1.5:\n",
        "        a = a / 255.0\n",
        "    return a\n",
        "\n",
        "\n",
        "def discover_basenames(pairs_dir: str) -> List[str]:\n",
        "    \"\"\"Find all core_*_HE.npy files with matching ORION.\"\"\"\n",
        "    d = Path(pairs_dir)\n",
        "    out = []\n",
        "    for hef in sorted(d.glob(\"core_*_HE.npy\")):\n",
        "        base = hef.stem.replace(\"_HE\", \"\")\n",
        "        if (d / f\"{base}_ORION.npy\").exists():\n",
        "            out.append(base)\n",
        "    return out\n",
        "\n",
        "\n",
        "class QuantileScaler:\n",
        "    \"\"\"Global per-channel quantile normalization.\"\"\"\n",
        "    def __init__(self, q_low=1.0, q_high=99.5, C=20):\n",
        "        self.q_low = q_low\n",
        "        self.q_high = q_high\n",
        "        self.qlo = np.zeros(C, dtype=np.float32)\n",
        "        self.qhi = np.ones(C, dtype=np.float32)\n",
        "        self.C = C\n",
        "\n",
        "    @classmethod\n",
        "    def from_dict(cls, d: Dict):\n",
        "        obj = cls(d.get(\"q_low\", 1.0), d.get(\"q_high\", 99.5), d.get(\"C\", 20))\n",
        "        obj.qlo = np.array(d[\"qlo\"], dtype=np.float32)\n",
        "        obj.qhi = np.array(d[\"qhi\"], dtype=np.float32)\n",
        "        return obj\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, path: Path):\n",
        "        return cls.from_dict(json.loads(path.read_text()))\n",
        "\n",
        "    def scale_to_log(self, orion: np.ndarray) -> np.ndarray:\n",
        "        C = self.C\n",
        "        out = np.zeros_like(orion, dtype=np.float32)\n",
        "        for c in range(C):\n",
        "            x = (orion[..., c] - self.qlo[c]) / (self.qhi[c] - self.qlo[c] + 1e-6)\n",
        "            x = np.clip(x, 0, None)\n",
        "            out[..., c] = np.log1p(x)\n",
        "        return out\n",
        "\n",
        "    def inverse_log(self, log_data: np.ndarray) -> np.ndarray:\n",
        "        return np.expm1(log_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Model Definition (for inference)\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "if HAS_TORCH and HAS_TIMM:\n",
        "    class SwinUNet(nn.Module):\n",
        "        def __init__(self, out_ch: int = 20, base_ch: int = 192, softplus_beta: float = 1.0):\n",
        "            super().__init__()\n",
        "            self.enc = timm.create_model(\n",
        "                'swin_tiny_patch4_window7_224', pretrained=False, features_only=True, out_indices=(0,1,2,3)\n",
        "            )\n",
        "            enc_chs = self.enc.feature_info.channels()\n",
        "            self.lats = nn.ModuleList([nn.Conv2d(c, base_ch, 1) for c in enc_chs])\n",
        "            self.smooth3 = nn.Sequential(nn.Conv2d(base_ch, base_ch, 3, padding=1), nn.ReLU(inplace=True))\n",
        "            self.smooth2 = nn.Sequential(nn.Conv2d(base_ch, base_ch, 3, padding=1), nn.ReLU(inplace=True))\n",
        "            self.smooth1 = nn.Sequential(nn.Conv2d(base_ch, base_ch, 3, padding=1), nn.ReLU(inplace=True))\n",
        "            self.smooth0 = nn.Sequential(nn.Conv2d(base_ch, base_ch//2, 3, padding=1), nn.ReLU(inplace=True))\n",
        "            self.out = nn.Conv2d(base_ch//2, out_ch, 1)\n",
        "            self.softplus = nn.Softplus(beta=softplus_beta)\n",
        "\n",
        "        def forward(self, x):\n",
        "            feats = self.enc(x)\n",
        "            feats = [f.permute(0, 3, 1, 2) for f in feats]\n",
        "            f3 = self.lats[3](feats[3])\n",
        "            f2 = self._upsum(f3, self.lats[2](feats[2]))\n",
        "            f2 = self.smooth3(f2)\n",
        "            f1 = self._upsum(f2, self.lats[1](feats[1]))\n",
        "            f1 = self.smooth2(f1)\n",
        "            f0 = self._upsum(f1, self.lats[0](feats[0]))\n",
        "            f0 = self.smooth1(f0)\n",
        "            up = F.interpolate(f0, size=x.shape[-2:], mode='bilinear', align_corners=False)\n",
        "            up = self.smooth0(up)\n",
        "            y = self.out(up)\n",
        "            y = self.softplus(y)\n",
        "            return y\n",
        "\n",
        "        @staticmethod\n",
        "        def _up(x, size_hw):\n",
        "            return F.interpolate(x, size=size_hw, mode='bilinear', align_corners=False)\n",
        "\n",
        "        def _upsum(self, x_small, x_skip):\n",
        "            x_up = self._up(x_small, x_skip.shape[-2:])\n",
        "            return x_up + x_skip\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def slide_reconstruct(model, he_img, tf_eval, ps=224, stride=112, device=\"cpu\"):\n",
        "        H, W, _ = he_img.shape\n",
        "        out_accum = None\n",
        "        weight = None\n",
        "        for y in range(0, max(1, H - ps) + 1, stride):\n",
        "            for x in range(0, max(1, W - ps) + 1, stride):\n",
        "                he_crop = (he_img[y:y+ps, x:x+ps, :] * 255).astype(np.uint8)\n",
        "                he_t = tf_eval(he_crop).unsqueeze(0).to(device)\n",
        "                pred_log = model(he_t).detach().cpu().numpy()[0]\n",
        "                if out_accum is None:\n",
        "                    C = pred_log.shape[0]\n",
        "                    out_accum = np.zeros((C, H, W), dtype=np.float32)\n",
        "                    weight = np.zeros((1, H, W), dtype=np.float32)\n",
        "                y2 = min(H, y + ps)\n",
        "                x2 = min(W, x + ps)\n",
        "                ph, pw = y2 - y, x2 - x\n",
        "                out_accum[:, y:y2, x:x2] += pred_log[:, :ph, :pw]\n",
        "                weight[:, y:y2, x:x2] += 1.0\n",
        "        return out_accum / np.clip(weight, 1e-6, None)\n",
        "\n",
        "    print(\"âœ… Model class defined\")\n",
        "else:\n",
        "    print(\"â„¹ï¸ Model not available - view-only mode\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Load Data and Model\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "# Discover cores\n",
        "pairs_dir = Path(PAIRS_DIR)\n",
        "if not pairs_dir.exists():\n",
        "    raise FileNotFoundError(f\"âŒ Data directory not found: {PAIRS_DIR}\")\n",
        "\n",
        "BASENAMES = discover_basenames(PAIRS_DIR)\n",
        "print(f\"âœ… Found {len(BASENAMES)} paired cores\")\n",
        "\n",
        "# Load scaler\n",
        "scaler = None\n",
        "model = None\n",
        "tf_eval = None\n",
        "\n",
        "if CHECKPOINT_PATH and Path(CHECKPOINT_PATH).exists() and HAS_TORCH and HAS_TIMM:\n",
        "    print(f\"Loading model from {CHECKPOINT_PATH}...\")\n",
        "    ckpt = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n",
        "    model = SwinUNet(out_ch=20, base_ch=192, softplus_beta=1.0)\n",
        "    model.load_state_dict(ckpt[\"model\"])\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "    if \"scaler\" in ckpt:\n",
        "        scaler = QuantileScaler.from_dict(ckpt[\"scaler\"])\n",
        "    tf_eval = T.Compose([\n",
        "        T.ToPILImage(),\n",
        "        T.Resize(PATCH_SIZE, antialias=True),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    print(\"âœ… Model loaded!\")\n",
        "\n",
        "if scaler is None and SCALER_PATH and Path(SCALER_PATH).exists():\n",
        "    scaler = QuantileScaler.load(Path(SCALER_PATH))\n",
        "    print(\"âœ… Scaler loaded from file\")\n",
        "\n",
        "if scaler is None:\n",
        "    scaler = QuantileScaler(q_low=1.0, q_high=99.5, C=N_CHANNELS)\n",
        "    print(\"â„¹ï¸ Using default scaler (no quantile normalization)\")\n",
        "\n",
        "HAS_MODEL = model is not None\n",
        "print(f\"\\nğŸ¯ Mode: {'Prediction + GT' if HAS_MODEL else 'View-only (GT only)'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Data Loading Functions with Caching\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "_cache = {}\n",
        "\n",
        "def load_core(basename: str):\n",
        "    \"\"\"Load H&E and ORION for a core (with caching).\"\"\"\n",
        "    if basename in _cache:\n",
        "        return _cache[basename]\n",
        "    \n",
        "    he = np.load(pairs_dir / f\"{basename}_HE.npy\")\n",
        "    orion = np.load(pairs_dir / f\"{basename}_ORION.npy\")\n",
        "    \n",
        "    if orion.ndim == 3 and orion.shape[0] == N_CHANNELS:\n",
        "        orion = np.transpose(orion, (1, 2, 0))\n",
        "    \n",
        "    he = _np_to_float01(he)\n",
        "    orion = _np_to_float01(orion)\n",
        "    \n",
        "    _cache[basename] = (he, orion)\n",
        "    return he, orion\n",
        "\n",
        "\n",
        "def get_prediction(basename: str, he: np.ndarray):\n",
        "    \"\"\"Get model prediction (with caching).\"\"\"\n",
        "    cache_key = f\"{basename}_pred\"\n",
        "    if cache_key in _cache:\n",
        "        return _cache[cache_key]\n",
        "    \n",
        "    if not HAS_MODEL:\n",
        "        return None\n",
        "    \n",
        "    pred_log = slide_reconstruct(model, he, tf_eval, ps=PATCH_SIZE, stride=STRIDE, device=DEVICE)\n",
        "    _cache[cache_key] = pred_log\n",
        "    return pred_log\n",
        "\n",
        "\n",
        "def compute_metrics(gt, pred):\n",
        "    \"\"\"Compute comparison metrics.\"\"\"\n",
        "    gt_flat = gt.flatten()\n",
        "    pred_flat = pred.flatten()\n",
        "    mse = np.mean((gt_flat - pred_flat) ** 2)\n",
        "    mae = np.mean(np.abs(gt_flat - pred_flat))\n",
        "    if gt_flat.std() > 1e-8 and pred_flat.std() > 1e-8:\n",
        "        corr = np.corrcoef(gt_flat, pred_flat)[0, 1]\n",
        "    else:\n",
        "        corr = 0.0\n",
        "    return {\"MSE\": mse, \"MAE\": mae, \"Pearson r\": corr}\n",
        "\n",
        "print(\"âœ… Loading functions ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# ğŸ® INTERACTIVE VIEWER - Run this cell!\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "# Create widgets\n",
        "core_dropdown = widgets.Dropdown(\n",
        "    options=[(f\"{b} ({i+1}/{len(BASENAMES)})\", b) for i, b in enumerate(BASENAMES)],\n",
        "    value=BASENAMES[0],\n",
        "    description='Core:',\n",
        "    style={'description_width': '60px'},\n",
        "    layout=widgets.Layout(width='300px')\n",
        ")\n",
        "\n",
        "channel_dropdown = widgets.Dropdown(\n",
        "    options=[(f\"Ch {i}: {MARKER_NAMES[i]}\", i) for i in range(N_CHANNELS)],\n",
        "    value=0,\n",
        "    description='Channel:',\n",
        "    style={'description_width': '60px'},\n",
        "    layout=widgets.Layout(width='250px')\n",
        ")\n",
        "\n",
        "cmap_dropdown = widgets.Dropdown(\n",
        "    options=COLORMAPS,\n",
        "    value='viridis',\n",
        "    description='Colormap:',\n",
        "    style={'description_width': '60px'},\n",
        "    layout=widgets.Layout(width='180px')\n",
        ")\n",
        "\n",
        "vmin_slider = widgets.FloatSlider(\n",
        "    value=0.0, min=0.0, max=1.0, step=0.01,\n",
        "    description='V Min:',\n",
        "    style={'description_width': '50px'},\n",
        "    layout=widgets.Layout(width='250px')\n",
        ")\n",
        "\n",
        "vmax_slider = widgets.FloatSlider(\n",
        "    value=0.5, min=0.0, max=2.0, step=0.01,\n",
        "    description='V Max:',\n",
        "    style={'description_width': '50px'},\n",
        "    layout=widgets.Layout(width='250px')\n",
        ")\n",
        "\n",
        "show_hist_check = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description='Show Histogram',\n",
        "    layout=widgets.Layout(width='150px')\n",
        ")\n",
        "\n",
        "prev_button = widgets.Button(description='â—€ Prev', layout=widgets.Layout(width='80px'))\n",
        "next_button = widgets.Button(description='Next â–¶', layout=widgets.Layout(width='80px'))\n",
        "\n",
        "output = widgets.Output()\n",
        "\n",
        "\n",
        "def update_view(*args):\n",
        "    \"\"\"Update the visualization.\"\"\"\n",
        "    with output:\n",
        "        clear_output(wait=True)\n",
        "        \n",
        "        basename = core_dropdown.value\n",
        "        channel = channel_dropdown.value\n",
        "        cmap = cmap_dropdown.value\n",
        "        vmin = vmin_slider.value\n",
        "        vmax = vmax_slider.value\n",
        "        \n",
        "        # Load data\n",
        "        print(f\"Loading {basename}...\", end=\" \")\n",
        "        he, orion = load_core(basename)\n",
        "        gt_log = scaler.scale_to_log(orion)\n",
        "        print(\"âœ“\")\n",
        "        \n",
        "        # Get prediction if available\n",
        "        pred_log = None\n",
        "        if HAS_MODEL:\n",
        "            print(\"Running inference...\", end=\" \")\n",
        "            pred_log = get_prediction(basename, he)\n",
        "            print(\"âœ“\")\n",
        "        \n",
        "        # Create figure\n",
        "        n_cols = 3 if pred_log is not None else 2\n",
        "        fig_width = 5 * n_cols\n",
        "        fig, axes = plt.subplots(1, n_cols, figsize=(fig_width, 5))\n",
        "        if n_cols == 2:\n",
        "            axes = list(axes)\n",
        "        \n",
        "        # H&E\n",
        "        axes[0].imshow(he)\n",
        "        axes[0].set_title(f\"H&E â€” {basename}\", fontsize=10)\n",
        "        axes[0].axis('off')\n",
        "        \n",
        "        # Ground Truth\n",
        "        gt_ch = scaler.inverse_log(gt_log[..., channel])\n",
        "        im_gt = axes[1].imshow(gt_ch, cmap=cmap, vmin=vmin, vmax=vmax)\n",
        "        axes[1].set_title(f\"Ground Truth â€” {MARKER_NAMES[channel]}\", fontsize=10)\n",
        "        axes[1].axis('off')\n",
        "        plt.colorbar(im_gt, ax=axes[1], fraction=0.046, pad=0.04)\n",
        "        \n",
        "        # Prediction\n",
        "        if pred_log is not None:\n",
        "            pred_ch = scaler.inverse_log(pred_log[channel])\n",
        "            im_pred = axes[2].imshow(pred_ch, cmap=cmap, vmin=vmin, vmax=vmax)\n",
        "            axes[2].set_title(f\"Prediction â€” {MARKER_NAMES[channel]}\", fontsize=10)\n",
        "            axes[2].axis('off')\n",
        "            plt.colorbar(im_pred, ax=axes[2], fraction=0.046, pad=0.04)\n",
        "            \n",
        "            # Metrics\n",
        "            metrics = compute_metrics(gt_ch, pred_ch)\n",
        "            metrics_str = \" | \".join([f\"{k}: {v:.4f}\" for k, v in metrics.items()])\n",
        "            fig.suptitle(metrics_str, fontsize=9, y=0.02)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        # Histogram\n",
        "        if show_hist_check.value:\n",
        "            fig_hist, ax_hist = plt.subplots(figsize=(10, 3))\n",
        "            ax_hist.hist(gt_ch.flatten(), bins=100, alpha=0.7, label=\"Ground Truth\", color=\"#00d4aa\")\n",
        "            if pred_log is not None:\n",
        "                ax_hist.hist(pred_ch.flatten(), bins=100, alpha=0.7, label=\"Prediction\", color=\"#ff6b6b\")\n",
        "            ax_hist.set_xlabel(\"Intensity\")\n",
        "            ax_hist.set_ylabel(\"Frequency\")\n",
        "            ax_hist.set_title(f\"Intensity Distribution â€” {MARKER_NAMES[channel]}\")\n",
        "            ax_hist.legend()\n",
        "            ax_hist.set_xlim(0, max(vmax, 1.0))\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "\n",
        "def on_prev_click(b):\n",
        "    idx = BASENAMES.index(core_dropdown.value)\n",
        "    if idx > 0:\n",
        "        core_dropdown.value = BASENAMES[idx - 1]\n",
        "\n",
        "\n",
        "def on_next_click(b):\n",
        "    idx = BASENAMES.index(core_dropdown.value)\n",
        "    if idx < len(BASENAMES) - 1:\n",
        "        core_dropdown.value = BASENAMES[idx + 1]\n",
        "\n",
        "\n",
        "# Connect widgets\n",
        "core_dropdown.observe(update_view, names='value')\n",
        "channel_dropdown.observe(update_view, names='value')\n",
        "cmap_dropdown.observe(update_view, names='value')\n",
        "vmin_slider.observe(update_view, names='value')\n",
        "vmax_slider.observe(update_view, names='value')\n",
        "show_hist_check.observe(update_view, names='value')\n",
        "prev_button.on_click(on_prev_click)\n",
        "next_button.on_click(on_next_click)\n",
        "\n",
        "# Layout\n",
        "controls_row1 = widgets.HBox([core_dropdown, channel_dropdown, cmap_dropdown])\n",
        "controls_row2 = widgets.HBox([vmin_slider, vmax_slider, show_hist_check])\n",
        "nav_row = widgets.HBox([prev_button, next_button])\n",
        "\n",
        "display(widgets.VBox([\n",
        "    widgets.HTML(\"<h2>ğŸ”¬ HEXIF Core Viewer</h2>\"),\n",
        "    controls_row1,\n",
        "    controls_row2,\n",
        "    nav_row,\n",
        "    output\n",
        "]))\n",
        "\n",
        "# Initial render\n",
        "update_view()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Multi-Channel Overview (Run to see all channels at once)\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "def show_all_channels(basename: str, cmap: str = 'viridis'):\n",
        "    \"\"\"Display all channels for a single core.\"\"\"\n",
        "    he, orion = load_core(basename)\n",
        "    gt_log = scaler.scale_to_log(orion)\n",
        "    \n",
        "    n_cols = 5\n",
        "    n_rows = (N_CHANNELS + n_cols - 1) // n_cols\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 3 * n_rows))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    for ch in range(N_CHANNELS):\n",
        "        ch_data = scaler.inverse_log(gt_log[..., ch])\n",
        "        axes[ch].imshow(ch_data, cmap=cmap, vmin=0, vmax=0.5)\n",
        "        axes[ch].set_title(f\"{MARKER_NAMES[ch]}\", fontsize=9)\n",
        "        axes[ch].axis('off')\n",
        "    \n",
        "    for i in range(N_CHANNELS, len(axes)):\n",
        "        axes[i].axis('off')\n",
        "    \n",
        "    fig.suptitle(f\"All Channels â€” {basename}\", fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Uncomment and run to see all channels for the first core:\n",
        "# show_all_channels(BASENAMES[0], cmap='magma')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Batch Export (Save comparison images for all cores)\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "def batch_export(output_dir: str, channels: list = [0, 1, 2, 3, 4], cmap: str = 'viridis'):\n",
        "    \"\"\"Export comparison images for all cores.\"\"\"\n",
        "    out_path = Path(output_dir)\n",
        "    out_path.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    for i, basename in enumerate(BASENAMES):\n",
        "        print(f\"Processing {basename} ({i+1}/{len(BASENAMES)})...\", end=\" \")\n",
        "        \n",
        "        he, orion = load_core(basename)\n",
        "        gt_log = scaler.scale_to_log(orion)\n",
        "        pred_log = get_prediction(basename, he) if HAS_MODEL else None\n",
        "        \n",
        "        n_cols = 3 if pred_log is not None else 2\n",
        "        for ch in channels:\n",
        "            fig, axes = plt.subplots(1, n_cols, figsize=(4*n_cols, 4))\n",
        "            \n",
        "            axes[0].imshow(he)\n",
        "            axes[0].set_title(\"H&E\")\n",
        "            axes[0].axis('off')\n",
        "            \n",
        "            gt_ch = scaler.inverse_log(gt_log[..., ch])\n",
        "            axes[1].imshow(gt_ch, cmap=cmap, vmin=0, vmax=0.5)\n",
        "            axes[1].set_title(f\"GT: {MARKER_NAMES[ch]}\")\n",
        "            axes[1].axis('off')\n",
        "            \n",
        "            if pred_log is not None:\n",
        "                pred_ch = scaler.inverse_log(pred_log[ch])\n",
        "                axes[2].imshow(pred_ch, cmap=cmap, vmin=0, vmax=0.5)\n",
        "                axes[2].set_title(f\"Pred: {MARKER_NAMES[ch]}\")\n",
        "                axes[2].axis('off')\n",
        "            \n",
        "            plt.tight_layout()\n",
        "            fig.savefig(out_path / f\"{basename}_ch{ch:02d}_{MARKER_NAMES[ch]}.png\", dpi=150, bbox_inches='tight')\n",
        "            plt.close(fig)\n",
        "        \n",
        "        print(\"âœ“\")\n",
        "    \n",
        "    print(f\"\\nâœ… Exported to {out_path}\")\n",
        "\n",
        "# Uncomment to export:\n",
        "# batch_export(\"viewer_exports\", channels=[0, 1, 5, 7, 15])"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
